# Preprunning : stopping parameter so that the tree is not too deep 
# Prostprunning: removing or collapsing nodes
# Feature importance to see rate of each feature in the prediction
# Decision tree regressor does not extrapolate
# Resulting model easy to visualize, algo invariant of the scaling cool with 
# features mixing binary and continuous